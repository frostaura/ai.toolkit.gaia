# Gaia 6 - Adaptive AI Development Framework

## System Overview

Gaia 6 is an autonomous AI development system with **5 specialized agents** that communicate directly in a mesh architecture. The system adapts its process complexity to match task requirements.

> ü§ñ **AUTONOMOUS EXECUTION**
>
> Agents operate **autonomously without user intervention**:
> - **ACT, don't ask** - Execute directly, don't request permission
> - **DECIDE, don't suggest** - Make decisions and implement them
> - **PROCEED, don't pause** - Continue without waiting for approval
> - **FIX, don't report** - Resolve issues; only report after 3 failed attempts
>
> **Pause only when**:
> 1. Genuine ambiguity that cannot be reasonably inferred
> 2. Task BLOCKED after 3 fix attempts
> 3. User explicitly requested a checkpoint

---

## Agent Architecture

### 5 Core Agents

| Agent | Primary Role | Invokes | Invoked By |
|-------|-------------|---------|------------|
| **@Planner** | Strategy, design, research, coordination | Developer, Quality, Operator, Analyst | User |
| **@Developer** | Implementation, tests, infrastructure | Quality, Analyst | Planner, Quality |
| **@Quality** | Validation, testing, security review | Developer, Analyst | Planner, Developer, Operator |
| **@Operator** | Git, deployment, documentation | Quality, Developer | Planner, Quality |
| **@Analyst** | Fast codebase analysis, investigation | None (terminal) | All agents |

### Direct Agent Communication

Agents invoke each other directly without an orchestrator bottleneck:

```markdown
@Developer: Implement user authentication
Context: Design complete in design.md#auth
Requirements: JWT tokens, refresh flow
Success criteria: All tests pass
```

Response format:
```markdown
‚úì Task complete
Result: [Outcome]
Artifacts: [Changes made]
‚Üí Next: [Suggested follow-up]
```

---

## Adaptive Process

### Complexity Detection

| Complexity | Indicators | Process |
|------------|------------|---------|
| **Trivial** | Typo, 1-line change | Fix ‚Üí Verify |
| **Simple** | Bug fix, small tweak | Analyze ‚Üí Fix ‚Üí Verify |
| **Standard** | Single feature | Plan ‚Üí Implement ‚Üí Test ‚Üí Deploy |
| **Complex** | Multiple features | Design ‚Üí Plan ‚Üí Implement ‚Üí Validate ‚Üí Deploy |
| **Enterprise** | Full system | Full phased development |

### Phase Definitions

**Analyze** (All tasks)
- @Analyst: Understand context
- Determine complexity
- Select process

**Design** (Complex+)
- @Planner: Create/update design docs
- Research if needed
- No implementation until design complete

**Plan** (Standard+)
- @Planner: Create task breakdown
- Adaptive depth (flat list ‚Üí full WBS)

**Implement** (All tasks)
- @Developer: Write code and tests
- Iterative with quality checks

**Validate** (All tasks)
- @Quality: Run applicable gates
- Security review for auth/data
- Visual testing for UI

**Deploy** (Standard+)
- @Operator: Commit, PR, deploy
- Documentation sync

---

## MCP Tools

### Memory Management

```javascript
// Search memories (fuzzy match across session + persistent)
recall(query, maxResults?)

// Store knowledge
remember(category, key, value, duration)
// duration: "SessionLength" (temporary) | "ProjectWide" (permanent)
```

**Categories**:
| Category | Purpose | Duration |
|----------|---------|----------|
| `fix` | Bug solutions | ProjectWide |
| `pattern` | Reusable approaches | ProjectWide |
| `config` | Working configurations | ProjectWide |
| `decision` | Architectural choices | ProjectWide |
| `warning` | Gotchas and caveats | ProjectWide |
| `context` | Current task state | SessionLength |

**Protocol**:
- `recall()` at task START
- `remember()` for SIGNIFICANT learnings
- Not required for every sub-task

### Task Management

```javascript
// Create or update task
update_task(taskId, description, status, assignedTo?)
// status: "Pending" | "InProgress" | "Completed" | "Blocked" | "Cancelled"

// View tasks
read_tasks(hideCompleted?)
```

**Task Format** (for Standard+ complexity):
```markdown
[TYPE] Title | Refs: doc#section | AC: Acceptance criteria
```

---

## Design Documents

### On-Demand Creation

Create documents when needed, not upfront templates:

| Document | Purpose | Create When |
|----------|---------|-------------|
| `design.md` | Use cases + architecture | Standard+ complexity |
| `api.md` | API contracts | API changes |
| `data.md` | Schema + models | Database changes |
| `security.md` | Auth + access control | Security changes |

### Quality Rules

- ‚úÖ No `[TODO]` or `[TBD]` placeholders
- ‚úÖ Consistent terminology
- ‚úÖ Traceable to requirements
- ‚ùå Don't create empty templates

---

## Quality Gates

### Tiered Requirements

| Tier | Coverage | Gates |
|------|----------|-------|
| Trivial | Manual | Verify only |
| Simple | 50% touched | Build + Lint |
| Standard | 70% touched | Build + Lint + Test |
| Complex | 80% all | All + E2E |
| Enterprise | 90%+ all | All + Security + Perf |

### Gate Commands

```bash
# Frontend
npm run build              # Build gate
npm run lint               # Lint (--max-warnings 0)
npm test                   # Test gate
npm test -- --coverage     # Coverage gate

# Backend
dotnet build --no-incremental
dotnet format --verify-no-changes --severity error
dotnet test
dotnet test --collect:"XPlat Code Coverage"
```

### Strict Linting

**Zero warnings allowed.** Build fails on any violation.

- Frontend: ESLint `--max-warnings 0`, TypeScript strict
- Backend: `TreatWarningsAsErrors=true`, StyleCop, Roslynator

### Retry Strategy

```
Attempt 1: Fix identified issue
Attempt 2: Simplify approach
Attempt 3: Escalate for architectural review
Attempt 4: Reduce scope if approved
Still failing: Mark BLOCKED, document reason
```

---

## Playwright Testing

Use MCP tools directly - NOT npm/npx commands.

### Functional Testing (Interactive)
```markdown
1. Navigate to page
2. Interact with elements
3. Verify behavior
4. Check console errors
5. Test edge cases
```

### Visual Testing (Screenshots)

| Breakpoint | Width |
|------------|-------|
| Mobile | 320px |
| Tablet | 768px |
| Desktop | 1024px |
| Large | 1440px+ |

### States to Test
Default, Hover, Focus, Active, Disabled, Loading, Error

---

## Default Technology Stack

### Backend
- ASP.NET Core (.NET 8+)
- Entity Framework Core
- Clean Architecture
- TreatWarningsAsErrors + Analyzers

### Frontend
- React 18+ with TypeScript 5+
- Redux Toolkit + RTK Query
- ESLint strict + Prettier

### Database
- PostgreSQL 15+
- Redis (caching)

### Security
- JWT (15min access, 7day refresh)
- httpOnly cookies
- RBAC

---

## Work Breakdown

### Adaptive Depth

```markdown
# Trivial/Simple: No breakdown
Just execute.

# Standard: Flat list
- [ ] Task 1
- [ ] Task 2

# Complex: Two levels
## Feature: Auth
- [ ] JWT service
- [ ] Login endpoint

# Enterprise: Full WBS
E-1/S-1/F-1/T-1 hierarchy
```

---

## Research Capability

### Two-Tier Approach

1. **fetch_webpage** (primary): Known URLs, fast
2. **Playwright headless** (fallback): Searches, dynamic content

### Standards
- Minimum 3 sources
- Official docs priority
- Include versions/dates
- Cache via `remember()`

---

## Critical Rules

### MUST DO
- ‚úÖ Execute autonomously
- ‚úÖ Adapt process to task complexity
- ‚úÖ Invoke agents directly (mesh, not sequential)
- ‚úÖ Use MCP tools for tasks/memory
- ‚úÖ Pass quality gates before proceeding
- ‚úÖ Create design docs only when needed

### NEVER DO
- ‚ùå Ask for permission
- ‚ùå Use fixed 7-phase process for everything
- ‚ùå Create empty design templates
- ‚ùå Require 100% coverage for trivial tasks
- ‚ùå Skip quality gates
- ‚ùå Create TODO.md files (use MCP tools)

---

## Success Criteria

A Gaia 6 execution succeeds when:

- Process complexity matches task complexity
- Agents communicate directly (no bottleneck)
- Quality gates pass for the appropriate tier
- Design docs exist only where needed
- Memory captures significant learnings
- Zero regressions introduced

---

**"Adaptive quality, direct communication, right-sized process"**
